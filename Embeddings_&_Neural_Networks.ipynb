{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shriya-tiwari/NLP-B_Tech_Project/blob/main/Embeddings_%26_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCae11s9gKvN"
      },
      "source": [
        "# Continuous Bag of Words (CBOW)\n",
        "predicts the current word given context words within a specific window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW09ufkBgePY",
        "outputId": "50c0836d-8ee6-4a98-b3e8-6f7e5df00f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzMReo4incIE",
        "outputId": "dcdac100-3208-48d4-fb7b-dae717b065e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM-GowbCjY2B"
      },
      "outputs": [],
      "source": [
        "sample = open(\"/content/sample_data/sample_text.txt\")\n",
        "s = sample.read().replace(\"\\n\", \" \")\n",
        "s = re.sub(r'[^\\w\\s]', '', s)\n",
        "sw = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for i in sent_tokenize(s):\n",
        "    temp = []\n",
        "    for j in word_tokenize(i):\n",
        "      j = j.lower()\n",
        "      j = lemmatizer.lemmatize(j)\n",
        "      if j not in sw:\n",
        "        temp.append(j)\n",
        "    # print(temp)\n",
        "\n",
        "    data.append(temp)"
      ],
      "metadata": {
        "id": "vTpPcYRxnXi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2JnPE7Hmr0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859133d8-fbaa-43dc-facb-cf76321bc9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['dynamic', 'realm', 'technological', 'advancement', 'innovation', 'stand', 'driving', 'force', 'intertwining', 'technology', 'shape', 'landscape', 'progress', 'symbiotic', 'relationship', 'technology', 'innovation', 'evident', 'every', 'facet', 'modern', 'existence', 'witness', 'evolution', 'smartphones', 'artificial', 'intelligence', 'internet', 'thing', 'becomes', 'clear', 'technology', 'serf', 'canvas', 'upon', 'innovation', 'paint', 'profound', 'stroke', 'breakthrough', 'technology', 'often', 'herald', 'leap', 'innovation', 'vice', 'versa', 'creating', 'continuous', 'loop', 'advancement', 'consider', 'transformative', 'impact', 'technology', 'healthcare', 'innovation', 'medical', 'device', 'telemedicine', 'data', 'analytics', 'revolutionizing', 'patient', 'care', 'technology', 'becomes', 'enabler', 'innovation', 'fostering', 'novel', 'approach', 'diagnosis', 'treatment', 'healthcare', 'delivery', 'business', 'landscape', 'fusion', 'technology', 'innovation', 'driving', 'factor', 'success', 'company', 'embrace', 'cuttingedge', 'technology', 'foster', 'culture', 'innovation', 'find', 'forefront', 'industry', 'automation', 'datadriven', 'decisionmaking', 'disruptive', 'business', 'model', 'technology', 'provides', 'platform', 'innovative', 'strategy', 'flourish', 'education', 'undergoing', 'metamorphosis', 'collaboration', 'technology', 'innovation', 'digital', 'learning', 'platform', 'virtual', 'reality', 'classroom', 'adaptive', 'learning', 'system', 'reshaping', 'way', 'knowledge', 'imparted', 'relationship', 'evident', 'technology', 'fuel', 'innovative', 'method', 'enhance', 'educational', 'experience', 'yet', 'relationship', 'without', 'challenge', 'rapid', 'pace', 'technological', 'change', 'demand', 'corresponding', 'agility', 'fostering', 'innovation', 'adapting', 'new', 'technology', 'leveraging', 'innovative', 'solution', 'requires', 'mindset', 'embrace', 'change', 'commitment', 'staying', 'forefront', 'progress', 'summary', 'interplay', 'technology', 'innovation', 'central', 'theme', 'fastpaced', 'world', 'word', 'embedding', 'model', 'text', 'provides', 'ample', 'instance', 'term', 'technology', 'innovation', 'cooccur', 'allowing', 'model', 'capture', 'semantic', 'relationship']]\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLo4ygC6navJ"
      },
      "outputs": [],
      "source": [
        "#CBOW model with vector_size = 100 and window size = 5\n",
        "model_CBOW = gensim.models.Word2Vec(data, min_count = 1, vector_size = 150, window = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA4w742Yn0j7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb072c8-0ade-4449-817b-cd74dc69d15d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('knowledge', 0.22922463715076447),\n",
              " ('educational', 0.20184476673603058),\n",
              " ('yet', 0.1762729287147522),\n",
              " ('imparted', 0.1481236219406128),\n",
              " ('factor', 0.14173272252082825),\n",
              " ('advancement', 0.1357717216014862),\n",
              " ('reality', 0.13518062233924866),\n",
              " ('way', 0.1329987347126007),\n",
              " ('often', 0.1326533406972885),\n",
              " ('summary', 0.13243314623832703)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model_CBOW.wv.most_similar('education')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cosine similarity between 'advancement' \" + \"and 'education' - CBOW : \",\n",
        "    model_CBOW.wv.similarity('advancement', 'education'))"
      ],
      "metadata": {
        "id": "LakKot6E0TrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a78e7c-12f6-4692-d2aa-73e192c5635d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'advancement' and 'education' - CBOW :  0.13577172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skip Gram Model\n",
        "predicts the surrounding context words within specific window given current word"
      ],
      "metadata": {
        "id": "mL7HpKhZ0u2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_SG = gensim.models.Word2Vec(data, min_count = 1, vector_size = 100, window = 5, sg = 1)\n",
        "\n",
        "print(\"Cosine similarity between 'advancement' \" +  \"and 'education' - Skip Gram : \", model_SG.wv.similarity('advancement', 'education'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7kdqoRf4w9b",
        "outputId": "2117d1a5-d6a9-44b7-e14a-a6375f2e27b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'advancement' and 'education' - Skip Gram :  0.07274586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_SG.wv.most_similar('education')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUGZOsc35BvH",
        "outputId": "054f7cb9-6ebf-4062-8326-0d57b4b10766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('provides', 0.20022395253181458),\n",
              " ('word', 0.1918536126613617),\n",
              " ('digital', 0.16173812747001648),\n",
              " ('collaboration', 0.1552039533853531),\n",
              " ('thing', 0.15253496170043945),\n",
              " ('virtual', 0.15200799703598022),\n",
              " ('method', 0.14484526216983795),\n",
              " ('embrace', 0.13881103694438934),\n",
              " ('becomes', 0.1368793249130249),\n",
              " ('serf', 0.1344384402036667)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis using TFIDF and neural network"
      ],
      "metadata": {
        "id": "jGewuH0vAWmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import seaborn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "seaborn.set(style='whitegrid'); seaborn.set_context('talk')\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "metadata": {
        "id": "q6TCS9xIAh4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "dataset = pandas.read_csv('/content/amazon_cells_labelled.csv')"
      ],
      "metadata": {
        "id": "_KXcQGzIAjr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset['statement']\n",
        "y = dataset['sentiment']\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "CeyGMiXaAwRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pRnMONZYA2yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wGpDpAdA5sf",
        "outputId": "93149623-fad5-4215-fdf1-6558e3d085d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29                                  Doesn't hold charge.\n",
            "535    All it took was one drop from about 6 inches a...\n",
            "695           Do NOT buy if you want to use the holster.\n",
            "557    I have purchased these for both family and fri...\n",
            "836                        Horrible, horrible protector.\n",
            "Name: statement, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=3000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "XNI_I5bvA8C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_final = X_train_tfidf.toarray()\n",
        "X_test_final = X_test_tfidf.toarray()"
      ],
      "metadata": {
        "id": "ar4NfY8-BCcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_final = pd.DataFrame(X_train_final)\n",
        "X_test_final = pd.DataFrame(X_test_final)"
      ],
      "metadata": {
        "id": "c9UQkBoqBL77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, learning_rate, epochs):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.randn(self.input_dim, self.hidden_dim)\n",
        "        self.bias_hidden = np.zeros((1, self.hidden_dim))\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_dim, self.output_dim)\n",
        "        self.bias_output = np.zeros((1, self.output_dim))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            # Forward pass\n",
        "            hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "            hidden_output = self.sigmoid(hidden_input)\n",
        "            output_input = np.dot(hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "            output = self.sigmoid(output_input)\n",
        "\n",
        "            # Backpropagation\n",
        "            error = y - output\n",
        "            d_output = error * self.sigmoid_derivative(output)\n",
        "            error_hidden = d_output.dot(self.weights_hidden_output.T)\n",
        "            d_hidden = error_hidden * self.sigmoid_derivative(hidden_output)\n",
        "\n",
        "            # Update weights and biases\n",
        "            self.weights_hidden_output += hidden_output.T.dot(d_output) * self.learning_rate\n",
        "            self.bias_output += np.sum(d_output, axis=0, keepdims=True) * self.learning_rate\n",
        "            self.weights_input_hidden += X.T.dot(d_hidden) * self.learning_rate\n",
        "            self.bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * self.learning_rate\n",
        "\n",
        "    def predict(self, X):\n",
        "        hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        hidden_output = self.sigmoid(hidden_input)\n",
        "        output_input = np.dot(hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        output = self.sigmoid(output_input)\n",
        "        return output\n",
        "\n",
        "# Initialize and train the MLP\n",
        "input_dim = X_train_tfidf.shape[1]  # Number of TF-IDF features\n",
        "hidden_dim = 500\n",
        "output_dim = 1  # Binary classification\n",
        "learning_rate = 0.1\n",
        "epochs = 1000\n",
        "\n",
        "mlp = MLP(input_dim, hidden_dim, output_dim, learning_rate, epochs)\n",
        "mlp.train(X_train_final, y_train.values.reshape(-1, 1))\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = mlp.predict(X_test_final)\n",
        "\n",
        "# Evaluate the model (you can use various metrics)\n",
        "accuracy = np.mean((y_pred > 0.5) == y_test.values.reshape(-1, 1))\n",
        "print(f'Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kVnNyR9BcUV",
        "outputId": "2985f269-46d9-41da-fb6c-44766ea7af7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.54\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/oCYlo2PQYbLRO9ZHE94K",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}